# Instructions
- Refer to *RL-Assignment_1.pdf* to know the exact task at hand.
- *bandit_env.py* contains the environment for the multi-armed bandit problem (it was provided with *RL-Assignment_1.pdf*).

- The code is in *map_mdp_code.ipynb*.

- For question 2 of the *RL-Assignment_1.pdf*, I haven't uploaded the MDP diagram. In the code, I am representing the different states, actions and transition probabilities through a nested list.

